import torch
import argparse
import time
import numpy as np
import os
from model.repvgg import get_RepVGG_func_by_name

def run_benchmark(model_name, model, device, image_size, warmup_runs=20, benchmark_runs=100):
    """
    è¿è¡ŒæŒ‡å®šæ¨¡å‹çš„åŸºå‡†æµ‹è¯•ã€‚

    :param model_name: æ¨¡å‹çš„å¯è¯»åç§°ï¼ˆä¾‹å¦‚ "è®­ç»ƒæ¨¡å‹"ï¼‰
    :param model: è¦æµ‹è¯•çš„ PyTorch æ¨¡å‹
    :param device: è¿è¡Œè®¾å¤‡ ('cpu' or 'cuda')
    :param image_size: è¾“å…¥å›¾åƒçš„å°ºå¯¸
    :param warmup_runs: é¢„çƒ­è¿è¡Œæ¬¡æ•°
    :param benchmark_runs: åŸºå‡†æµ‹è¯•è¿è¡Œæ¬¡æ•°
    :return: (å¹³å‡å»¶è¿Ÿ ms, å¹³å‡ååé‡ FPS)
    """
    model.to(device)
    model.eval()

    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥æ•°æ®
    dummy_input = torch.randn(1, 3, image_size, image_size, device=device)

    # é¢„çƒ­
    print(f"ğŸ”¥ ({model_name}) æ­£åœ¨é¢„çƒ­...")
    with torch.no_grad():
        for _ in range(warmup_runs):
            _ = model(dummy_input)

    # åŒæ­¥ç­‰å¾…GPUæ“ä½œå®Œæˆ
    if device.startswith('cuda'):
        torch.cuda.synchronize()

    # å¼€å§‹åŸºå‡†æµ‹è¯•
    print(f"ğŸš€ ({model_name}) æ­£åœ¨è¿è¡ŒåŸºå‡†æµ‹è¯•...")
    timings = []
    with torch.no_grad():
        for i in range(benchmark_runs):
            start_time = time.perf_counter()
            _ = model(dummy_input)
            if device.startswith('cuda'):
                torch.cuda.synchronize()
            end_time = time.perf_counter()
            timings.append(end_time - start_time)

    # è®¡ç®—å¹¶è¿”å›ç»“æœ
    avg_latency_ms = np.mean(timings) * 1000
    fps = 1 / np.mean(timings)
    print(f"âœ… ({model_name}) æµ‹è¯•å®Œæˆ!")
    return avg_latency_ms, fps

def benchmark(args):
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œæ¨¡å‹åŠ è½½å’ŒåŸºå‡†æµ‹è¯•æµç¨‹ã€‚
    """
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"â„¹ï¸ ä½¿ç”¨è®¾å¤‡: {device.upper()}")
    print(f"ğŸ“Š æ¨¡å‹: {args.model}, ç±»åˆ«æ•°: {args.num_classes}, å›¾åƒå°ºå¯¸: {args.image_size}x{args.image_size}\n")

    # --- 1. æµ‹è¯•è®­ç»ƒæ—¶æ¨¡å‹ (é‡å‚æ•°åŒ–å‰) ---
    print("="*40)
    print("ğŸ” å¼€å§‹æµ‹è¯•è®­ç»ƒæ—¶æ¨¡å‹ (å¤šåˆ†æ”¯ç»“æ„)")
    print("="*40)
    train_model_func = get_RepVGG_func_by_name(args.model)
    train_model = train_model_func(deploy=False)
    train_model.linear = torch.nn.Linear(train_model.linear.in_features, args.num_classes)

    if not os.path.exists(args.train_weights):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒæƒé‡æ–‡ä»¶ {args.train_weights}")
        return

    checkpoint = torch.load(args.train_weights, map_location=device)
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    else:
        state_dict = checkpoint
    train_model.load_state_dict(state_dict)
    print(f"âœ… æˆåŠŸåŠ è½½è®­ç»ƒæƒé‡: {args.train_weights}")

    train_latency, train_fps = run_benchmark("è®­ç»ƒæ¨¡å‹", train_model, device, args.image_size, args.warmup, args.runs)
    print(f"â±ï¸  è®­ç»ƒæ¨¡å‹å¹³å‡å»¶è¿Ÿ: {train_latency:.2f} ms")
    print(f"ğŸš€  è®­ç»ƒæ¨¡å‹å¹³å‡ååé‡: {train_fps:.2f} FPS\n")


    # --- 2. æµ‹è¯•éƒ¨ç½²æ—¶æ¨¡å‹ (é‡å‚æ•°åŒ–å) ---
    print("="*40)
    print("ğŸ” å¼€å§‹æµ‹è¯•éƒ¨ç½²æ—¶æ¨¡å‹ (å•å·ç§¯ç»“æ„)")
    print("="*40)
    deploy_model_func = get_RepVGG_func_by_name(args.model)
    deploy_model = deploy_model_func(deploy=True)
    deploy_model.linear = torch.nn.Linear(deploy_model.linear.in_features, args.num_classes)

    if not os.path.exists(args.deploy_weights):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°éƒ¨ç½²æƒé‡æ–‡ä»¶ {args.deploy_weights}")
        print(f"â„¹ï¸ æ‚¨å¯ä»¥ä½¿ç”¨ `convert.py` è„šæœ¬ç”Ÿæˆéƒ¨ç½²æƒé‡ã€‚")
        return

    deploy_model.load_state_dict(torch.load(args.deploy_weights, map_location=device))
    print(f"âœ… æˆåŠŸåŠ è½½éƒ¨ç½²æƒé‡: {args.deploy_weights}")

    deploy_latency, deploy_fps = run_benchmark("éƒ¨ç½²æ¨¡å‹", deploy_model, device, args.image_size, args.warmup, args.runs)
    print(f"â±ï¸  éƒ¨ç½²æ¨¡å‹å¹³å‡å»¶è¿Ÿ: {deploy_latency:.2f} ms")
    print(f"ğŸš€  éƒ¨ç½²æ¨¡å‹å¹³å‡ååé‡: {deploy_fps:.2f} FPS\n")


    # --- 3. æ€§èƒ½å¯¹æ¯” ---
    print("="*50)
    print("ğŸ‰ æ€§èƒ½å¯¹æ¯”æ€»ç»“ ğŸ‰")
    print("="*50)
    print(f"| {'æ¨¡å‹ç±»å‹':<12} | {'å¹³å‡å»¶è¿Ÿ (ms)':<18} | {'ååé‡ (FPS)':<15} |")
    print(f"|{'-'*14}|{'-'*20}|{'-'*17}|")
    print(f"| {'è®­ç»ƒæ¨¡å‹':<12} | {train_latency:<18.2f} | {train_fps:<15.2f} |")
    print(f"| {'éƒ¨ç½²æ¨¡å‹':<12} | {deploy_latency:<18.2f} | {deploy_fps:<15.2f} |")
    print("-" * 52)
    
    if train_fps > 0:
        speedup_factor = deploy_fps / train_fps
        print(f"\nâœ¨ é‡å‚æ•°åŒ–åï¼Œæ¨¡å‹é€Ÿåº¦æå‡äº† {speedup_factor:.2f} å€ï¼")
    
    print("="*50)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='RepVGG è®­ç»ƒä¸éƒ¨ç½²æ¨¡å‹æ¨ç†é€Ÿåº¦åŸºå‡†æµ‹è¯•')
    parser.add_argument('--model', type=str, default='RepVGG-A0', help='æ¨¡å‹åç§°ï¼Œå¦‚ RepVGG-A0')
    parser.add_argument('--train_weights', type=str, default='./checkpoints/RepVGG-A0_4/best.pth', help='è®­ç»ƒæƒé‡è·¯å¾„ (best.pth)')
    parser.add_argument('--deploy_weights', type=str, default='./checkpoints/RepVGG-A0_4/deploy.pth', help='éƒ¨ç½²æƒé‡è·¯å¾„ (deploy.pth)')
    parser.add_argument('--num_classes', type=int, default=2, help='åˆ†ç±»ç±»åˆ«æ•°')
    parser.add_argument('--image_size', type=int, default=224, help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--warmup', type=int, default=20, help='é¢„çƒ­è¿è¡Œæ¬¡æ•°')
    parser.add_argument('--runs', type=int, default=100, help='åŸºå‡†æµ‹è¯•è¿è¡Œæ¬¡æ•°')
    args = parser.parse_args()

    torch.set_num_threads(1)
    torch.set_num_interop_threads(1)

    benchmark(args) 